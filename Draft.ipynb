{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'models'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_53956\\224109474.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mpandas\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0msrc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrewards\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[1;33m*\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32md:\\Studies\\CSE-546\\Final_Project\\EDG_DeepRL\\src\\rewards.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtransformers\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mAutoTokenizer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mAutoModelForSequenceClassification\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mEmpathyModel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mempathy_classifier\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mEmpathyClassifier\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_available\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\Studies\\CSE-546\\Final_Project\\EDG_DeepRL\\src\\EmpathyModel\\empathy_classifier.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mTensorDataset\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrandom_split\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     22\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 23\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mmodels\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodels\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mBiEncoderAttentionWithRationaleClassification\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     24\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtransformers\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mAdamW\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mRobertaConfig\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     25\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'models'"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import pandas\n",
    "from src.rewards import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import GPT2PreTrainedModel, GPT2Model\n",
    "from transformers import GPT2Tokenizer\n",
    "from transformers import PYTORCH_PRETRAINED_BERT_CACHE, cached_path\n",
    "from transformers import GPT2Config, GPT2Model, GPT2Config\n",
    "from transformers import GPT2Tokenizer, GPT2LMHeadModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = GPT2Tokenizer.from_pretrained('gpt2')\n",
    "model = GPT2LMHeadModel.from_pretrained('gpt2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>seeker_post</th>\n",
       "      <th>response_post</th>\n",
       "      <th>level</th>\n",
       "      <th>rationale_labels</th>\n",
       "      <th>rationale_labels_trimmed</th>\n",
       "      <th>response_post_masked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3079</th>\n",
       "      <td>8jltcy_dz0kvhi</td>\n",
       "      <td>does anyone else keep forgetting stuff the nee...</td>\n",
       "      <td>All day, every day. It's definitely not just y...</td>\n",
       "      <td>1</td>\n",
       "      <td>0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,...</td>\n",
       "      <td>35</td>\n",
       "      <td>All day, every day. It's definitely not just y...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3080</th>\n",
       "      <td>94xc3o_e3ok8c0</td>\n",
       "      <td>What does depression feel like?. Honest questi...</td>\n",
       "      <td>like being stuck in a black hole. At times you...</td>\n",
       "      <td>0</td>\n",
       "      <td>0,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,...</td>\n",
       "      <td>117</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3081</th>\n",
       "      <td>3zbq8e_cykvlsj</td>\n",
       "      <td>I'm to scared to commit suicide.. All I can fe...</td>\n",
       "      <td>I probably would have considered bringing harm...</td>\n",
       "      <td>0</td>\n",
       "      <td>0,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,...</td>\n",
       "      <td>125</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3082</th>\n",
       "      <td>5kpp98_dbpqi2p</td>\n",
       "      <td>I just want to disappear but I don't want to h...</td>\n",
       "      <td>People barely notice me too</td>\n",
       "      <td>0</td>\n",
       "      <td>0,1,1,1,1,1,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,...</td>\n",
       "      <td>11</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3083</th>\n",
       "      <td>7gqrti_dqz05c5</td>\n",
       "      <td>26 year old male, living at home, low income j...</td>\n",
       "      <td>I see what you mean, but imagine being 26, liv...</td>\n",
       "      <td>0</td>\n",
       "      <td>0,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,...</td>\n",
       "      <td>125</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  id                                        seeker_post  \\\n",
       "3079  8jltcy_dz0kvhi  does anyone else keep forgetting stuff the nee...   \n",
       "3080  94xc3o_e3ok8c0  What does depression feel like?. Honest questi...   \n",
       "3081  3zbq8e_cykvlsj  I'm to scared to commit suicide.. All I can fe...   \n",
       "3082  5kpp98_dbpqi2p  I just want to disappear but I don't want to h...   \n",
       "3083  7gqrti_dqz05c5  26 year old male, living at home, low income j...   \n",
       "\n",
       "                                          response_post  level  \\\n",
       "3079  All day, every day. It's definitely not just y...      1   \n",
       "3080  like being stuck in a black hole. At times you...      0   \n",
       "3081  I probably would have considered bringing harm...      0   \n",
       "3082                        People barely notice me too      0   \n",
       "3083  I see what you mean, but imagine being 26, liv...      0   \n",
       "\n",
       "                                       rationale_labels  \\\n",
       "3079  0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,...   \n",
       "3080  0,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,...   \n",
       "3081  0,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,...   \n",
       "3082  0,1,1,1,1,1,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,...   \n",
       "3083  0,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,...   \n",
       "\n",
       "      rationale_labels_trimmed  \\\n",
       "3079                        35   \n",
       "3080                       117   \n",
       "3081                       125   \n",
       "3082                        11   \n",
       "3083                       125   \n",
       "\n",
       "                                   response_post_masked  \n",
       "3079  All day, every day. It's definitely not just y...  \n",
       "3080                                                NaN  \n",
       "3081                                                NaN  \n",
       "3082                                                NaN  \n",
       "3083                                                NaN  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pandas.read_csv(\"..\\\\Empathy-Mental-Health\\\\dataset\\\\emotional-reactions-reddit-output.csv\")\n",
    "data.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Embedding(50260, 768)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "special_tokens = {\n",
    "    'bos_token': \"<bos>\",\n",
    "    'additional_special_tokens': [\"<speaker1>\", \"<speaker2>\"]\n",
    "}\n",
    "\n",
    "num_new_tokens = tokenizer.add_special_tokens(special_tokens)\n",
    "vocab = tokenizer.get_vocab()\n",
    "model.resize_token_embeddings(len(vocab))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Conversation:\n",
    "\n",
    "    def __init__(self, seq_gen):\n",
    "        self.seq_gen = seq_gen\n",
    "        self.history = list()\n",
    "\n",
    "    def step(self, sentence):\n",
    "        self.memory.append(sentence)\n",
    "        response = self.seq_gen.predict(sentence)\n",
    "        return response\n",
    "    \n",
    "    def train(self, seq_gen, episodes = 100, lr=0.001, batch_size = 32, seed = 10):\n",
    "        pass\n",
    "\n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def degree_empathy(seeker_post, response_post):\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_rewards(current, future):\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
